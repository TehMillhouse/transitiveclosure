\documentclass[12pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath}
\usepackage{algorithm, algpseudocode}
\usepackage{adjustbox}
\usepackage{url}

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\reachable}{reachable}

\begin{document}

\title{Fast Transitive Closure Computation}
\author{Max Wagner \and Sebastian Ullrich}
\date{August 2014}
\maketitle

\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}

\newcommand\ie{i.e.\ }
\newcommand\eg{e.g.,\ }
\newcommand\credits[1]{\begin{flushright}\emph{#1}\end{flushright}}
\newcommand\abs[1]{\left|#1\right|}
\newcommand\BigOh[1]{\mathcal{O}\left(#1\right)}

\begin{abstract}
  In this paper, we discuss and evaluate various algorithms for computing the transitive closure of a directed acyclic graph (DAG). The algorithms are implemented on top of a generic, template-based framework to make them independent from the input and output representation, where possible.
\end{abstract}

\section{Introduction}

The problem of computing the transitive closure $E^+$ of a directed acyclic graph $G = (V,E)$ is a rather well-known one, and over the years a number of different algorithms have been devised to compute solutions. In this paper, we deliver implementations of several of these algorithms on top of a graph framework written in C++ and evaluate the performance of these algorithms. Our implementation computes the reflexive-transitive closure $E^*$, as this simplified algorithm design. As our input graphs are acyclic, this is only a trivial change. The complete source code of this framework along with the implementations of the different algorithms is available on Github\footnote{\url{https://github.com/tehmillhouse/transitiveclosure/}}.

\section{The Graph Framework}

While an adjacency matrix is the most natural representation of transitive closures since it can answer reachability queries in constant time, its size of $\abs{V}^2$ bits can quickly outgrow a computer's main memory, even though the closure itself may be relatively sparse for realistic inputs. For this reason, we decided to implement adjacency lists and arrays as additional output formats and make the implementations independent of the actual format by use of C++ templates. Naturally, not every algorithm can be implemented for every output format, as will be noted below.

\subsection{Adjacency Array}

The \verb|AdjacencyArrayGraph| class stores its edges' target nodes in a contiguous array. Each node references a range in that array as its outgoing edges.

In order to fill an instance of \verb|AdjacencyArrayGraph|, one uses its method \verb|void pushNode()| to add a new node, followed by zero or more invocations of \verb|void pushEdge(int v)| to add its outgoing edges. While this strictly sequential interface is the most restrictive one, it also guarantees a minimum of cache misses for constructing the output graph. Likewise, it could trivially be extended into a semi-external algorithm (where only the input graph has to fit in memory) by writing the output directly to disk.

\subsection{Adjacency List}

The \verb|AdjacencyListGraph| class holds a separate array of outgoing edges per node. In addition to \verb|AdjacencyArrayGraph|'s interface, it supports the method \verb|void addEdge(int u, int v)| for non-sequential (\eg parallel) construction of the output graph.

\subsection{Adjacency Matrix}

The \verb|AdjacencyMatrixGraph| stores adjacency data in a $\abs{V} \times \abs{V}$ bit matrix. In addition to the interfaces mentioned above, it supports random access via the method \verb|bool hasEdge(int u, int v)|.

Specifically, the matrix is encoded as a column-major contiguous array of \verb|uint64_t|s holding adjacency information of 64 target nodes (including padding, if necessary). This allows fast bit-wise operations on whole columns via the method \verb|uint64_t* rawCol(int u)|.

\section{Single-Source Algorithms}
\credits{Sebastian Ullrich}

By first solving the graph reachability problem starting from a single source node $u$, which we will call $\reachable(u) := \{v \in V | (u, v) \in E^*\}$, we can easily compose the whole closure: $E^* = \{(u, v) | u \in V, v \in \reachable(u)\}$. Both breadth-first search (BFS) and depth-first search (DFS) are well-known algorithms for solving the reachability problem in $\BigOh{\abs{E}}$ time, yielding a total run time of $\BigOh{\abs{V} \abs{E}}$. Topological level search (TLS) can be regarded as a variant of BFS where nodes are visited in order of increasing topological level. This doesn't change the asymptotic run time, but can potentially improve cache efficiency because nodes of the same topological level are likely to share successor nodes. A pseudo code implementation is shown in Algorithm~\ref{algo:TLS}.

\begin{algorithm}
  \begin{algorithmic}
    \Function{TLS}{s}
      \State find topological levels
      \State $next[level(s)] \gets \{s\}$
      \For{$l \gets level(s), maxLevel$}
        \For{$u \in next[l]$}
          \State $visited[u] \gets false$
          \For{$v \in V, (u,v) \in E$}
            \If{$\neg visited[v]$}
              \State $visited[v] \gets true$
              \State $reachable[s, v] \gets true$
              \State $next[level(v)] \gets next[level(v)] \cup \{v\}$
            \EndIf
          \EndFor
        \EndFor
        \State $next[l] \gets \emptyset$ \Comment Optimization: reset for next invocation
      \EndFor
    \EndFunction
  \end{algorithmic}
  \caption{Topological Level Search}
  \label{algo:TLS}
\end{algorithm}

As a small optimization, we can avoid having to reset the whole \emph{visited} array by saving the reached nodes in a list in addition to the \emph{reached} bit array and explicitly resetting only those nodes. This is even easier for TLS, as evidenced by Algorithm~\ref{algo:TLS}, because a node cannot be reached any more once it has been visited.

Since the individual executions of a single-source algorithm are independent of each other, the three algorithms are embarassingly parallel problems. We have implemented this for BFS, yielding \emph{paraBFS}.

\section{Bit-Parallel TLS}
\credits{Sebastian Ullrich}

As a first improvement over the single-source algorithms, we can reduce the expected number of graph traversals by generalizing the algorithms to traverse a whole set $S$ of start nodes at the same time; Algorithm~\ref{algo:MultiTLS} shows such a straightforward extension for TLS. Selecting the nodes in $S$ from the same topological level is a good heuristics for finding nodes whose reachable subgraphs overlap maximally. If we furthermore restrict the size of $S$ to the hardware word size $w$, we can efficiently implement the set operations on \emph{visited} by native bitwise operations, yielding a \emph{bit-parallel} implementation (\emph{TLS64} in case of the 64-bit target system).

Note, however, that while this reduces the set operations to constant time, the loop iterating over all set bits of \emph{visited[u]} still needs $w$ iterations. So for sparse graphs there is a non-negligible overhead over basic TLS even though the rest of the algorithm graciously degrades to the single-source implementation in that situation. Even for adjacency matrix outputs, we cannot simplify the loop to a constant-time word move since choosing $S$ from topological levels means its nodes will in general not be contiguous in the output matrix. As a potential future extension, one could allow algorithms to permute the order of nodes in the output in order to implement this optimization.

\begin{algorithm}
  \begin{algorithmic}
    \Function{TLS}{S}
      \State find topological levels
      \For{$s \in S$}
        \State $next[level(s)] \gets next[level(s)] \cup \{s\}$
        \State $visited[s] \gets \{s\}$
      \EndFor
      \For{$l \gets \min \{level(s) | s \in S\} , maxLevel$}
        \For{$u \in next[l]$}
          \For{$s \in visited[u]$}
            \State $reachable[s, u] \gets true$
          \EndFor
          \State $visited[u] \gets \emptyset$
          \For{$v \in V, (u,v) \in E$}
            \If{$visited[v] = \emptyset$}
              \State $next[level(v)] \gets next[level(v)] \cup \{v\}$
            \EndIf
            \State $visited[v] \gets visited[v] \cup visited[u]$
          \EndFor
        \EndFor
        \State $next[l] \gets \emptyset$ \Comment Optimization: reset for next invocation
      \EndFor
    \EndFunction
  \end{algorithmic}
  \caption{Multi-Source TLS}
  \label{algo:MultiTLS}
\end{algorithm}

\section{All-Sources Algorithms}
\credits{Floyd-Warshall: Tobias Fleck \\
         RecMerge: Sebastian Ullrich \\
         RTLS: Max Wagner}

The Floyd-Warshall algorithm is a well known solution to the all-pairs shortest path problem and therefore can also be used to compute the transitive closure. However, its run time of $\mathcal{O}(\abs{V}^3)$ makes it prohibitively expensive compared to the other algorithms on the usually sparse input graphs.

In order to find an efficient all-sources algorithm, \eg one that reuses intermediate results such as \emph{reachable}, we can use the following recursive definition of \emph{reachable}:

\begin{equation}
  \reachable(u) = \{u\} \cup \bigcup_{\substack{v \\ (u, v) \in E}} \reachable(v)
  \label{reachable-rec}
\end{equation}

The RecMerge algorithm simply evaluates this definition recursively for all $u \in V$, reusing \emph{reachable} values that have already been computed; Note that the recursion will always terminate on finite DAGs. Reverse Topological Level Search (RTLS) is also based on the formula, but visits nodes in descending order of topological level, which ensures that all $\reachable(v)$ on the right-hand side have already been computed. As an immediate advantage over RecMerge, RTLS can trivially be parallelized (paraRTLS): Since nodes in the same topological level are not adjacent, their \emph{reachable} columns can be computed in parallel.

The only thing left to do is to find an efficient implementation for equation~(\ref{reachable-rec}) itself. For the adjacency matrix output, this is a bitwise \emph{or} of $deg^+(u)$ columns, yielding a total run time of $\BigOh{\sum_{u \in V} deg^+(u) \frac{\abs{V}}{w}} = \BigOh{\frac{\abs{V} \abs{E}}{w}}$. For the adjacency list output, we walk through all $\reachable(v)$ and use a bit array to detect duplicate nodes. By using the same trick as with BFS for resetting this array, we can achieve a run time of

\begin{align*}
\BigOh{\sum_{u \in V} \sum_{\substack{v \\ (u, v) \in E}} \abs{\reachable(v)}}
&= \BigOh{\sum_{v \in V} \deg^-(v) \abs{\reachable(v)}} \\
&\subset \BigOh{\sum_{v \in V} \abs{V} \abs{\reachable(v)}} \\
&= \BigOh{\abs{V} \abs{E^*}}
\end{align*}

\section{Evaluation}

Our test results are listed in table~\ref{results}. Experiments were performed using a machine with two Intel Xeon X5355 CPUs (4 cores each, Hyperthreading disabled) running at 2.66 GHz; L2 cache is 2 $\times$ 4MB per physical CPU, L1 cache is 4 $\times$ 64KB per physical CPU distributed equally between instruction and data cache. The test machine has 24GB of RAM.
%% TODO: figure out what type of RAM we have.
The system is running Ubuntu 12.04.5 on Linux version 3.2.0. All code was compiled using gcc 4.9.0 on optimization level \texttt{O3}.

% generated by latexify.py
\input{table}

\subsection{Test Data}

The graphs used for these experiments were adopted from~\cite{preach}. The different classes of instances are the following:
\begin{description}
  \item{\textbf{Large Real:}} \verb|citeseer| is a citation network graph, \verb|uniprotenc-22m| is a subset of the UniProt RDF graph.
  \item{\textbf{Rand10k:}} These are randomly generated graphs with 10000 nodes.
  \item{\textbf{Rand1m:}} These are randomly generated graphs with 1000000 nodes.
  \item{\textbf{Small Real Dense:}} These graphs are mostly obtained from citation networks. All of them have previously been used by~\cite{Jin:2009:HIS:1559845.1559930}.
  \item{\textbf{Small Real Sparse:}} These graphs have an average degree less than 1.22 and less then
    40 000 nodes. xmark and nase represent XML documents; amaze and kegg are metabolic
    networks. The others are from from BioCyc~\cite{grail}. They represent pathway and genome
    databases.
  \item{\textbf{Small Scalefree:}} Are relatively small (10000 nodes) scale-free networks.
  \item{\textbf{Stanford:}} Graphs originating from the Stanford Large Network Dataset Collection. Currently only includes a graph of the Gnutella peer-to-peer network from 2002.
%%  \item{\textbf{TFRand:}} XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX TODO: where do these come from? The name implies they're from TF-Label...
\end{description}

\section{Conclusion}

The evaluation shows that \emph{parallel RTLS} is the fastest algorithm on the most instances, followed by \emph{parallel BFS}. For a completely sequential algorithm, \emph{RecMerge} shows surprisingly good performance, especially on sparse graphs.  As expected, the bit-parallel \emph{TLS64} performs better than \emph{TLS} on dense graphs, but worse on sparse graphs.

For the single-source algorithms and \emph{TLS64}, adjacency arrays are generally the fastest output format (where implemented), followed by adjacency lists. For the all-sources algorithms, the run times of adjacency lists and matrices can greatly differ in either direction, in accordance with the asymptotic run times.

Interestingly, for most graphs the best algorithm is just as fast or even faster than the precalculation phase of \emph{PReaCH}, even though the former computes the complete closure.


\bibliographystyle{apalike}
\bibliography{main}

\end{document}
