\documentclass[12pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath}
\usepackage{algorithm, algpseudocode}
\usepackage{adjustbox}

\DeclareMathOperator*{\argmin}{\arg\!\min}

\begin{document}

\title{Fast Transitive Closure Computation}
\author{Max Wagner \and Sebastian Ullrich \and Tobias Fleck}
\date{August 2014}
\maketitle

\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}

\newcommand\ie{i.e.\ }
\newcommand\eg{e.g.,\ }
\newcommand\credits[1]{\begin{flushright}\emph{#1}\end{flushright}}

\begin{abstract}
  In this paper, we discuss and evaluate various algorithms for computing the transitive closure of a directed acyclic graph. The algorithms are implemented on top of a generic, template-based framework to make them independent from the input and output representation, where possible.
\end{abstract}

\section{Introduction}

\section{The Graph Framework}

While an adjacency matrix is the most natural representation of transitive closures since it can answer reachability queries in constant time, its size of $n^2$ bits can quickly outgrow a computer's main memory, even though the closure itself may be relatively sparse for realistic inputs. For this reason, we decided to implement adjacency lists and arrays as additional output formats and make the implementations independent of the actual format by use of C++ templates. Naturally, not every algorithm can be implemented for every output format, as will be noted below.

\subsection{Adjacency Array}

The \verb|AdjacencyArrayGraph| class stores its edges' target nodes in a contiguous array. Each node references a range in that array as its outgoing edges.

In order to fill an instance of \verb|AdjacencyArrayGraph|, one uses its method \verb|void pushNode()| to add a new node, followed by zero or more invocations of \verb|void pushEdge(int v)| to add its outgoing edges. While this strictly sequential interface is the most restrictive one, it also guarantees a minimum of cache misses for constructing the output graph. Likewise, it could be trivially extended into a semi-external algorithm (where only the input graph has to fit in memory) by writing the output directly to disk.

\subsection{Adjacency List}

The \verb|AdjacencyListGraph| class hold a separate array of outgoing edges per node. In addition to \verb|AdjacencyArrayGraph|'s interface, it supports the method \verb|void addEdge(int u, int v)| for non-sequential (\eg parallel) construction of the output graph.

\subsection{Adjacency Matrix}

The \verb|AdjacencyMatrixGraph| stores adjacency data in an $n \times n$ bit matrix. In addition to the interfaces mentioned above, it supports methods \verb|bool hasEdge(int u, int v)| and \verb|void addEdge(int u, int v)| for direct access to the matrix.

Specifically, the matrix is encoded as a column-major contiguous array of \verb|uint64_t|s holding adjacency information of 64 target nodes (including padding, if necessary). This allows fast bit-wise operations on whole columns via the method \verb|uint64_t* rawCol(int u)|.

\section{Single-Source Algorithms}
\credits{Sebastian Ullrich}

Both breadth-first search (BFS) and depth-first search (DFS) are well-known algorithms for computing the graph reachability starting from a single source node. Topological level search (TLS) can be regarded as a variant of BFS where nodes are visited in order of increasing topological level. A pseudo code implementation is shown in Algorithm~\ref{algo:TLS}.

\begin{algorithm}
  \begin{algorithmic}
    \Function{TLS}{s}
      \State find topological levels
      \State $next[level(s)] \gets \{s\}$
      \For{$l \gets level(s), maxLevel$}
        \For{$u \in next[l]$}
          \State $visited[u] \gets false$
          \For{$v \in V, (u,v) \in E$}
            \If{$\neg visited[v]$}
              \State $visited[v] \gets true$
              \State $reached[s, v] \gets true$
              \State $next[level(v)] \gets next[level(v)] \cup \{v\}$
            \EndIf
          \EndFor
        \EndFor
        \State $next[l] \gets \emptyset$ \Comment Optimization: reset for next invocation
      \EndFor
    \EndFunction
  \end{algorithmic}
  \caption{Topological Level Search}
  \label{algo:TLS}
\end{algorithm}

By separately computing reachability for each node in the graph, these single-source algorithms can compute the transitive closure in $\mathcal{O}(n(n+m))$. As a small optimization, we can avoid having to reset the whole $visited$ array by saving the reached nodes in a list in addition to the $reached$ bit array and explicitly resetting only those nodes. This is even easier for TLS, as evidenced by Algorithm~\ref{algo:TLS}, because a node cannot be reached any more once it has been visited.

\section{Bit-Parallel TLS}
\credits{Sebastian Ullrich}

As a first improvement over the single-source algorithms, we can reduce the expected number of graph traversals by generalizing the algorithms to traverse a whole set $S$ of start nodes at the same time; Algorithm~\ref{algo:MultiTLS} shows such a straightforward extension for TLS. Selecting the nodes in $S$ from the same topological level is a good heuristics for finding nodes whose reachable subgraphs overlap maximally. If we furthermore restrict the size of $S$ to the hardware word size $w$, we can efficiently implement the set operations on $visited$ by native bitwise operations, yielding a \emph{bit-parallel} implementation.

Note, however, that while this reduces the set operations to constant time, the loop iterating over all set bits of $visited[u]$ still needs $w$ iterations. So for sparse graphs there is a non-negligible overhead over basic TLS even though the rest of the algorithm graciously degrades to the single-source implementation in that situation. Even for adjacency matrix outputs, we cannot simplify the loop to a constant-time word move since choosing $S$ from topological levels means its nodes will in general not be contiguous in the output matrix. As a potential future extension, one could allow algorithms to permute the order of nodes in the output in order to implement this optimization.

\begin{algorithm}
  \begin{algorithmic}
    \Function{TLS}{S}
      \State find topological levels
      \For{$s \in S$}
        \State $next[level(s)] \gets next[level(s)] \cup \{s\}$
        \State $visited[s] \gets \{s\}$
      \EndFor
      \For{$l \gets \argmin_{s \in S} level(s), maxLevel$}
        \For{$u \in next[l]$}
          \For{$s \in visited[u]$}
            \State $reached[s, u] \gets true$
          \EndFor
          \State $visited[u] \gets \emptyset$
          \For{$v \in V, (u,v) \in E$}
            \If{$visited[v] = \emptyset$}
              \State $next[level(v)] \gets next[level(v)] \cup \{v\}$
            \EndIf
            \State $visited[v] \gets visited[v] \cup visited[u]$
          \EndFor
        \EndFor
        \State $next[l] \gets \emptyset$ \Comment Optimization: reset for next invocation
      \EndFor
    \EndFunction
  \end{algorithmic}
  \caption{Multi-Source TLS}
  \label{algo:MultiTLS}
\end{algorithm}

\section{All-Source Algorithms}
\credits{Floyd-Warshall: Tobias Fleck \\
         RecMerge: Sebastian Ullrich \\
         RTLS: Max Wagner}

\subsection{Reverse TLS}

One major drawback of TLS is that it simply iterates over all nodes, completely ignoring any information about topological levels. In the implementation discussed above, it is thus forced to walk the same parts of the graph many times. Reverse Topological Level Search is an alternate formulation of TLS which avoids this problem by iterating over nodes in reverse topological order; This way, by the time the algorithm processes a node, the transitive closure of all of its successors have already been computed, and the algorithm only needs to merge these intermediate results to obtain the transitive closure for the node. Algorithm~\ref{algo:RTLS} shows an implementation in pseudo code.

\begin{algorithm}[h]
  \begin{algorithmic}
    \Function{RTLS}{V}
    \State find topological levels
    \For{$n \in V$}  % oh god, I hate pseudocode
      \State $bucket[level(n)] \gets bucket[level(n)] \cup \{n\}$
    \EndFor
    \State $E' \gets \{(n,n) \mid n \in V\}$

    \For{$level \gets maxLevel$ \textbf{down to} $0$}
      \For{$n \in bucket[level]$}
        \State $E' \gets \Call{MergeSuccessors}{E, E', n}$
      \EndFor
    \EndFor
    \State \Return $(V, E')$
    \EndFunction
    \\
    \Function{MergeSuccessors}{E, E', n}
      \For{$(n,s) \in E$}
      \Comment For each successor $s$ of $n$...
        \For{$(s,u) \in E'$}
        \Comment For each reachable node $u$ from $s$...
          \If{$\neg reached[u]$}
            \State $reached[u] \gets true$
            \State $E' \gets E' \cup \{(n,u)\}$
          \EndIf
        \EndFor
      \EndFor
      \State \Return $E'$
    \EndFunction
  \end{algorithmic}
  \caption{Reverse TLS}
  \label{algo:RTLS}
\end{algorithm}

\subsection{RecMerge}

The Recursive Merge algorithm works through much of the same mechanisms as RTLS, except that instead of explicitly determining topological levels and processing the nodes according to the resulting schedule, RecMerge performs this calculation implicitly by recursing on each node's successors. Algorithm~\ref{algo:RecMerge} shows a pseudo code implementation which uses the procedure \verb|MergeSuccessors| introduced in Algorithm~\ref{algo:RTLS} (RTLS).

\begin{algorithm}[h]
\begin{algorithmic}
  \Function{RecursiveMerge}{V}
    \State $E' \gets \{(n, n) \mid n \in V \}$
    \For{$n \in V$}
      \If{$\neg visited[n]$}
        \State $E' \gets \Call{RecursiveMergeAux}{E, E', s}$
      \EndIf
    \EndFor
    \State \Return $E'$
  \EndFunction
  \\
  \Function{RecursiveMergeAux}{E, E', n}
    \State $visited[n] \gets true$
    \For{$(n, s) \in E$}
      \If{$\neg visited[s]$}
        \State $E' \gets \Call{RecursiveMergeAux}{E, E', s}$
      \EndIf
    \EndFor
    \State $\Return \Call{MergeSuccessors}{E, E', n}$
  \EndFunction
\end{algorithmic}
\caption{Recursive Merge}
\label{algo:RecMerge}
\end{algorithm}

\section{Parallelized Implementations}
\credits{Tobias Fleck}

\section{Evaluation}

Experiments were performed using a machine with two Intel Xeon X5355 CPUs (with Hyperthreading disabled) running at 2.66 GHz; L2 cache is 2 $\times$ 4MB per physical CPU, L1 cache is 4 $\times$ 64KB per physical CPU distributed equally between code and data cache. The test machine has 24GB of RAM.
%% TODO: figure out what type of RAM we have.
The system is running Ubuntu 12.04.5 on Linux version 3.2.0. All code was compiled using gcc 4.9.0 on optimization level \texttt{O3}.

\subsection{Test Data}

The graphs used for these experiments were adopted from~\cite{preach}. The different classes of instances are the following:
\begin{description}
  \item{\textbf{Large Real:}} \verb|citeseer| is a citation network graph, \verb|uniprotenc-22m| is a subset of the UniProt RDF graph.
  \item{\textbf{Rand10k:}} These are randomly generated graphs with 10000 nodes.
  \item{\textbf{Rand1m:}} These are randomly generated graphs with 1000000 nodes.
  \item{\textbf{Small Real Dense:}} These graphs are mostly obtained from citation networks. All of them have previously been used by~\cite{Jin:2009:HIS:1559845.1559930}.
  \item{\textbf{Small Real Sparse:}} These graphs have an average degree less than 1.22 and less then
    40 000 nodes. xmark and nase represent XML documents; amaze and kegg are metabolic
    networks. The others are from from BioCyc~\cite{grail}. They represent pathway and genome
    databases.
  \item{\textbf{Small Scalefree:}} Are relatively small (10000 nodes) scale-free networks.
  \item{\textbf{Stanford:}} Graphs originating from the Stanford Large Network Dataset Collection. Currently only includes a graph of the Gnutella peer-to-peer network from 2002.
  \item{\textbf{TFRand:}} XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX TODO: where do these come from? The name implies they're from TF-Label...
\end{description}


% generated by latexify.py
\input{table}

\section{Conclusion}

The evaluation shows that \emph{RecMerge} is the fastest algorithm on the most instances, followed by \emph{paraBFS}. For the most part, adjacency lists are the fastest output format for both algorithms, but especially for \emph{RecMerge}, adjacency matrices can be an order of magnitude slower or faster on a few instances.

To create a more fair comparison between the two algorithms, conclusions should be postponed until after RecMerge and/or RTLS have been parallelized.

\bibliographystyle{apalike}
\bibliography{main}

\end{document}
